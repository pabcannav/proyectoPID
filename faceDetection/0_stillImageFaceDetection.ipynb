{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still Image Face Detection - Basic Implementation\n",
    "\n",
    "First things first, we have to import all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the 'cv2' library (previously installed with this command ```pip install opencv-python```), allows us to use and redesign these functions, as we'll do later.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing face detection on an image\n",
    "The most basic way to detect a face out of an image is loading the preferred image and apply some calculations on it to detect them.\n",
    "To do so, we will be using some XML files, which contains the measurements of all the different distances between 2 points that can appear on a face. We can import those XML files via:\n",
    ">```python\n",
    ">cv2.CascadeClasifier(path)\n",
    ">```\n",
    "This function receives a path of the file to load and use it.<sup>[1]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a basic recognition algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../cascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads ```haarcascade_frontalface_default.xml``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_path = '../img/multImages.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "imgName = os.path.splitext(os.path.basename(img_path))[0]\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.05, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```img = cv2.imread(src)```: Reads an image\n",
    "- ```gray = cv2.cvtColor(src, colorScheme)```: This function apply a filter to the image (in this example a grayscale filter)\n",
    "- ```faces = face_cascade.detectMultiScale(image, scaleFactor, minNeighbors)```: This function receives some arguments:\n",
    "    - ```image``` argument, which is our grayscale image.\n",
    "    - ```scaleFactor``` argument, this number should be greater than 1.0, it determines the downscaling ratio of the image.<sup>[2]</sup>\n",
    "    - ```minNeighbors``` argument, is the minimum number of overlapping detections required to retain a detection result.<sup>[3]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ```for``` loop allows us to iterate through the face rectangles values (wich is the value returned in ```faces```variable). It consists of:\n",
    "- ```x```: Contains the left side x-axis coordinate of the rectangle.\n",
    "- ```y```: Contains the top side y-axis coordinate of the rectangle.\n",
    "- ```w```: Represents the width of the rectangle.\n",
    "- ```h```: Represents the height of the rectangle.\n",
    "\n",
    "```rectangle(img, point1, point2, color, thickness)``` functions has some attributes:\n",
    "- ```img``` attribute, is the image we are working with.\n",
    "- ```point1``` attribute, is the coordinate of the first point of the rectangle (top-left).\n",
    "- ```point2``` attribute, is the coordinate of the second point of the rectangle (bottom-right).\n",
    "- ```color``` attribute, is the color of the rectangle (color is blue because its codified as BGR  ```..., cv2.COLOR_BGR2GRAY)```).\n",
    "- ```thickness``` attribute, is the thickness of the rectangle borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Woodcutters face detection', img)\n",
    "cv2.imwrite('../img/'+imgName+'_face_detection.jpg', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we show the image via ```imshow(path)``` command.\n",
    "\n",
    "```imwrite(path)``` command allows us to store the generated image in a desired location.\n",
    "\n",
    "```waitkey(time)``` command avoids the program to freeze.\n",
    "\n",
    "> It's important to know that if we want to detect faces in a 3/4 profile, standard Haar classifiers like the one from OpenCV are not able to detect them accurately. To solve this, we could use a more advanced model such as a DNN (Deep Neural Network) or MTCNN (Multi-Task Cascaded Convolutional Neural Network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "[1] - When using ```cascadeClasifier(path)```, there's a difference between detecting faces within an image and a video. If we detect a group of faces on an image, we're detecting them on a single frame, but if we want to detect a group of faces (or a single face) in a video, we will be processing a sequence of frames (we'll be performing calculations on every single frame of the video).\n",
    "\n",
    "[2] - This downscaling attribute is useful to set a scale invariance. ```1.08``` value makes the algorithm more exhaustive, doing mre iterations and detecting faces with different scales, but at a slower processing speed. In the contrary, a ```1.3``` value, makes it faster but some detections may be lost (small or medium objects).\n",
    "\n",
    "[3] - A higher value of ```minNeighbors``` reduces false positives, but some valid detections may be lost as well. A lower value, ```e.g. minNeighbors=1``` may result in several detections, including false positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
