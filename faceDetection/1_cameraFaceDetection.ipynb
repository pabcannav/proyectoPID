{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection on a camera input - Basic Implementation\n",
    "\n",
    "This script will use the built-in camera (if we're using a laptop) or an external camera/webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to do all the imports as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing face detection on a video feed\n",
    "\n",
    "To detect a face from a videocamera source, we'll be importing some XML files as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../cascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../cascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first XML file detects frontal faces (it's the same XML we used before)\n",
    "\n",
    "The second one allows us eye recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m camera \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     success, frame \u001b[38;5;241m=\u001b[39m camera\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while (cv2.waitKey(1) == -1):\n",
    "    success, frame = camera.read()\n",
    "    if success:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```VideoCapture(camera)```: captures the video from the default system camera.\n",
    "- ```waitKey(delay)```: this function will wait for a ```delay``` time in miliseconds if a key is pressed.<sup>[1]</sup>\n",
    "- ```read()```: starts video capture.<sup>[2]</sup>\n",
    "- ```cvtColor(imgFrame, colorScheme)```: takes the frame of the video capture in wich the face is detected and applies a filter to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(120, 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```minSize``` attribute defines a minimum size of the object we're detecting.\n",
    "\n",
    "Now we will be iterating over the detected faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(\n",
    "        roi_gray, 1.1, 5, minSize=(40, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the faces, as we did in the image detection algorithm.\n",
    "\n",
    "```f[y,x]```: extracts a ROI (```Region Of Interest```) from the image.<sup>[3]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through the eyes and draw rectangles around them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (ex, ey, ew, eh) in eyes:\n",
    "    cv2.rectangle(frame, (x+ex, y+ey),\n",
    "                  (x+ex+ew, y+ey+eh), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we show the result of the manipulated image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Videocamera face detection', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "[1] - If set to ```0```, it will wait until any key is pressed. It returns the ASCII code of the pressed key. If no key is pressed in the ```delay``` time, the return code is ```-1```.\n",
    "\n",
    "[2] - this function returns a two-value tuple:\n",
    "- ```success```: Indicates if the captured frame is valid (```True``` or ```False```)\n",
    "- ```frame```: NumPy array of the captured frame.\n",
    "\n",
    "[3] - A ROI is a ```subimage``` from the original frame which is created as:\n",
    "\n",
    "- ```f```: MatLike object variable.\n",
    "- e.g. ```y:y+h```: selects the row range that will be extracted (vertical axis)\n",
    "- e.g. ```x:x+w```: selects the column range that will be extracted (horizontal axis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
